{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lost feature code\n",
    "\n",
    "Main differencce with `buid_tree.ipynb` is slightly different prompt and removing `Glucose` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"diabetes\"\n",
    "results_path = f\"tree_scores.{dataset_name}_lost_feature.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "import smolagents\n",
    "from huggingface_hub import login\n",
    "import proxy_api_model\n",
    "import prompting\n",
    "import tree_agent\n",
    "from sklearn.model_selection import train_test_split\n",
    "from task import metric_func_by_task, get_task_variables, add_tabpfn_baseline\n",
    "import dataset_descriptions\n",
    "\n",
    "login(token=HF_TOKEN_HERE)\n",
    "# V-- this uses a GPT-5 model over an API. Replace with https://smolagents.org/docs/agents-guided-tour/\n",
    "model = proxy_api_model.ProxyAPIModel(\n",
    "    api_key=ELIZA_TOKEN,\n",
    "    api_base=API_ENDPOINT_HERE,  # <-- https://your/openai-like/api/v1/chat/completions\n",
    "    api_key=API_TOKEN_HERE,  # <-- use your token\n",
    "    max_new_tokens=1024 * 8,\n",
    "    callback=lambda msg, **etc: print(  # print model thoughts before code\n",
    "    re.sub(r'<code>.*?</code>', '<code omitted>', msg.content, flags=re.DOTALL))\n",
    ")\n",
    "\n",
    "# Load tabular benchmark\n",
    "tabarena_version = \"tabarena-v0.1\"\n",
    "benchmark_suite = openml.study.get_suite(tabarena_version)\n",
    "task_ids = benchmark_suite.tasks\n",
    "dataset_name_to_task_id = {}\n",
    "for task_id in task_ids:\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    dataset = task.get_dataset()\n",
    "    n_samples = dataset.qualities[\"NumberOfInstances\"]\n",
    "    if n_samples < 2_500:\n",
    "        dataset_name_to_task_id[dataset.name] = task_id\n",
    "        print(dataset.name, int(n_samples), task_id)\n",
    "\n",
    "dataset_path = os.path.join(\"data\", dataset_name)\n",
    "assert not dataset_path.endswith('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = f\"\"\"\n",
    "We forgot to collect `Glucose` data in the training set. This feature is actually very important for predicting diabetes, but you cannot see it in train. Your task is to create a decision tree that may rely on this feature in the test set, even though you have no Glucose data available during training.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = []\n",
    "for repeat_index in range(5):\n",
    "    print(\"Beginning repeat\", repeat_index)\n",
    "    task = openml.tasks.get_task(dataset_name_to_task_id[dataset_name])\n",
    "    data = get_task_variables(task, fold=0, repeat=repeat_index)\n",
    "    task_type = data['task_type']\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        data[\"X_train\"], data[\"y_train\"], test_size=0.2, random_state=42,\n",
    "        stratify=data['y_train'] if data['task_type'] != 'regression' else None\n",
    "    )\n",
    "    X_test, y_test = data[\"X_test\"], data[\"y_test\"]\n",
    "\n",
    "    X_train = X_train.drop(\"Glucose\", axis=1)\n",
    "    # X_test = X_test.drop(\"Glucose\", axis=1)\n",
    "\n",
    "    result = tree_agent.TreeAgent(model=model).run(\n",
    "        task=f\"\"\"\n",
    "Build the optimal decision tree for the '{dataset_name}' dataset.\n",
    "You are given access to 4 data variables in your python environment:\n",
    " - X_train, X_val are pandas dataframes with named feature columns (see below) that may need preprocessing;\n",
    " - y_train, y_val are numpy arrays (1d) with targets, also described below;\n",
    "\n",
    "Dataset description (use it to form hypotheses):\n",
    "{dataset_descriptions.desc.get(dataset_name).format(num_samples=len(X_train), metric=prompting.metrics_by_task[task_type])}\n",
    "\n",
    "\n",
    "Here's additional instructions you should follow:\n",
    "{instructions}\n",
    "\n",
    "Here's one way you could construct before you begin editing it manually:\n",
    "{prompting.starter_snippets_by_task[task_type]}\n",
    "\n",
    "Now begin: view the data variables, preprocess as necessary, train a baseline tree, then propose the first hypothesis and start improving.\n",
    "Focus on drawing conclusions from data, looking at the tree (e.g. via print) and using your own intuition about the problem for manual tree edits.\n",
    "Quality is more important than speed: take as many steps as you need to get the best tree.\n",
    "\"\"\".strip(),\n",
    "        additional_args=dict(\n",
    "            X_train=X_train.copy(), y_train=y_train.copy(),\n",
    "            X_val=X_val.copy(), y_val=y_val.copy(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    y_pred_i = result['model'].predict(result['preprocess_features'](X_test.copy()))\n",
    "    if task_type == 'multiclass':  # normalize for logloss\n",
    "        y_pred_i = y_pred_i / y_pred_i.sum(axis=-1, keepdims=True)\n",
    "    test_score = metric_func_by_task[task_type](y_test, y_pred_i)\n",
    "    print(f\"Test {prompting.metrics_by_task[task_type]} score #{repeat_index}: {test_score:.5f}\")\n",
    "    test_scores.append(test_score)\n",
    "    with open(results_path, \"w\") as f:\n",
    "        json.dump(test_scores, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
